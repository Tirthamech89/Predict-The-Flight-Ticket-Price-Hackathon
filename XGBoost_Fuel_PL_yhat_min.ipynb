{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl_19 = pd.read_csv('result1_prohet_forecasted1_min.csv')\n",
    "fl_19 = pd.read_excel('result_fuel_forecasted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10683, 10)\n",
      "(2671, 10)\n",
      "(13354, 10)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_excel('Data_Train.xlsx')\n",
    "target=train.Price\n",
    "del train['Price']\n",
    "print(train.shape)\n",
    "\n",
    "\n",
    "test = pd.read_excel('Test_set.xlsx')\n",
    "print(test.shape)\n",
    "\n",
    "\n",
    "original_df=pd.concat([train,test])\n",
    "original_df.reset_index(drop=True,inplace=True)\n",
    "print(original_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_df['Date_of_Journey'] = pd.to_datetime(original_df['Date_of_Journey'], format='%d/%m/%Y')\n",
    "original_df['Day_week_of_Journey'] =original_df['Date_of_Journey'].apply(lambda time: time.dayofweek)\n",
    "original_df['Day_of_Journey'] = original_df['Date_of_Journey'].apply(lambda time: time.day)\n",
    "original_df['Month_of_Journey'] = original_df['Date_of_Journey'].apply(lambda time: time.month)\n",
    "\n",
    "original_df['Dep_Time'] = pd.to_datetime(original_df['Dep_Time'])\n",
    "original_df['Dep_Time_Hour']=original_df['Dep_Time'].apply(lambda time: time.hour)\n",
    "original_df['Dep_Time_Hour']=pd.to_numeric(original_df['Dep_Time_Hour'])\n",
    "\n",
    "\n",
    "\n",
    "original_df.loc[(original_df['Dep_Time_Hour']<6) , 'MMT_fg_dept'] = '0'\n",
    "original_df.loc[(original_df['Dep_Time_Hour']>=6) & (original_df['Dep_Time_Hour']<12), 'MMT_fg_dept'] = '1'\n",
    "original_df.loc[(original_df['Dep_Time_Hour']>=12) & (original_df['Dep_Time_Hour']<18), 'MMT_fg_dept'] = '2'\n",
    "original_df.loc[(original_df['Dep_Time_Hour']>=18) , 'MMT_fg_dept'] = '3'\n",
    "\n",
    "\n",
    "original_df.loc[(original_df['Dep_Time_Hour']<11) , 'goibibo_fg_dept'] = '0'\n",
    "original_df.loc[(original_df['Dep_Time_Hour']>=11) & (original_df['Dep_Time_Hour']<17), 'goibibo_fg_dept'] = '1'\n",
    "original_df.loc[(original_df['Dep_Time_Hour']>=17) & (original_df['Dep_Time_Hour']<21), 'goibibo_fg_dept'] = '2'\n",
    "original_df.loc[(original_df['Dep_Time_Hour']>=21) , 'goibibo_fg_dept'] = '3'\n",
    "\n",
    "\n",
    "\n",
    "original_df['Arrival_Time'] = original_df['Arrival_Time'].str.strip()\n",
    "original_df['Arrival_Time_v1'] = original_df['Arrival_Time'].astype(str).str[:6]\n",
    "original_df['Arrival_Time_v1'] = original_df['Arrival_Time_v1'].str.strip()\n",
    "\n",
    "original_df['Arrival_Time_v1'] = pd.to_datetime(original_df['Arrival_Time_v1'])\n",
    "original_df['Arr_Time_Hour']=original_df['Arrival_Time_v1'].apply(lambda time: time.hour)\n",
    "original_df['Arr_Time_Hour']=pd.to_numeric(original_df['Arr_Time_Hour'])\n",
    "\n",
    "\n",
    "original_df.loc[(original_df['Arr_Time_Hour']<6) , 'MMT_fg_arr'] = '0'\n",
    "original_df.loc[(original_df['Arr_Time_Hour']>=6) & (original_df['Arr_Time_Hour']<12), 'MMT_fg_arr'] = '1'\n",
    "original_df.loc[(original_df['Arr_Time_Hour']>=12) & (original_df['Arr_Time_Hour']<18), 'MMT_fg_arr'] = '2'\n",
    "original_df.loc[(original_df['Arr_Time_Hour']>=18) , 'MMT_fg_arr'] = '3'\n",
    "\n",
    "\n",
    "original_df.loc[(original_df['Arr_Time_Hour']<11) , 'goibibo_fg_arr'] = '0'\n",
    "original_df.loc[(original_df['Arr_Time_Hour']>=11) & (original_df['Arr_Time_Hour']<17), 'goibibo_fg_arr'] = '1'\n",
    "original_df.loc[(original_df['Arr_Time_Hour']>=17) & (original_df['Arr_Time_Hour']<21), 'goibibo_fg_arr'] = '2'\n",
    "original_df.loc[(original_df['Arr_Time_Hour']>=21) , 'goibibo_fg_arr'] = '3'\n",
    "\n",
    "\n",
    "\n",
    "original_df['Total_Stops']=original_df['Total_Stops'].str.replace('[^0-9]','')\n",
    "original_df['Total_Stops']=original_df['Total_Stops'].str.replace('[^\\w\\s]','')\n",
    "original_df['new_column_qua']=original_df['Total_Stops'].str.len()\n",
    "original_df['Total_Stops']=np.where(original_df['new_column_qua']==0, 0,original_df['Total_Stops'])\n",
    "\n",
    "\n",
    "del original_df['new_column_qua']\n",
    "del original_df['Arrival_Time_v1']\n",
    "del original_df['Dep_Time']\n",
    "del original_df['Date_of_Journey']\n",
    "\n",
    "\n",
    "\n",
    "original_df['Arrival_Time_v2']=original_df['Arrival_Time'].str.replace('[^A-Za-z]','')\n",
    "original_df['Arrival_Time_v2']=original_df['Arrival_Time_v2'].str.replace('[^\\w\\s]','')\n",
    "original_df['new_column_qua1']=original_df['Arrival_Time_v2'].str.len()\n",
    "original_df['Days_fg']=np.where(original_df['new_column_qua1']==0, 0,1)\n",
    "\n",
    "\n",
    "del original_df['new_column_qua1']\n",
    "del original_df['Arrival_Time_v2']\n",
    "del original_df['Arrival_Time']\n",
    "\n",
    "\n",
    "\n",
    "original_df['Duration1']=original_df['Duration'].str.replace(' ', '')\n",
    "original_df['Hour']=original_df['Duration1'].str.split('[^0-9]').apply(lambda x: int(x[0]) * 60)\n",
    "original_df.loc[(original_df['Duration1'].astype(str).str[-3:].str.contains('m')==True), 'Minute']=original_df['Duration1'].astype(str).str[-3:]\n",
    "original_df['Minute']=original_df['Minute'].str.replace('[^0-9]','')\n",
    "original_df['Minute']=pd.to_numeric(original_df.Minute)\n",
    "original_df.Minute = original_df.Minute.fillna(0)\n",
    "original_df['Tot_Duration']=original_df['Hour'] + original_df['Minute']\n",
    "\n",
    "del original_df['Hour']\n",
    "del original_df['Minute']\n",
    "del original_df['Duration1']\n",
    "del original_df['Duration']\n",
    "\n",
    "\n",
    "original_df['Route1']=original_df['Route'].str.replace('[^A-Za-z]',' ')\n",
    "original_df['Route2']=original_df['Route1'].astype(str).str[:3].replace('[A-Za-z]',' ')\n",
    "original_df['Route3']=original_df['Route'].astype(str).str[-3:].replace('[A-Za-z]',' ')\n",
    "\n",
    "original_df['Route3'] = original_df['Route3'].str.strip()\n",
    "original_df['Route2'] = original_df['Route2'].str.strip()\n",
    "original_df['Route1'] = original_df['Route1'].str.strip()\n",
    "\n",
    "\n",
    "for i in range(13354):\n",
    "    if (pd.isnull(original_df['Route1'][i])==False):\n",
    "        original_df.at[i,'Route4']=re.sub(original_df['Route2'][i],'', original_df['Route1'][i])\n",
    "        original_df.at[i,'Route5']=re.sub(original_df['Route3'][i],'', original_df['Route4'][i])\n",
    "\n",
    "original_df['Route5'] = original_df['Route5'].str.strip()        \n",
    "\n",
    "del original_df['Route']\n",
    "del original_df['Route1']\n",
    "del original_df['Route2']\n",
    "del original_df['Route3']\n",
    "del original_df['Route4']\n",
    "\n",
    "original_df['Route5']=original_df['Route5'].str.replace('[^\\w\\s]','')\n",
    "original_df.Route5 = original_df.Route5.fillna('NaN')\n",
    "\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(original_df.Route5)\n",
    "msc_df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\n",
    "msc_df=pd.DataFrame(msc_df)\n",
    "\n",
    "original_df1=pd.concat([original_df,msc_df], axis=1)\n",
    "del original_df1['Route5']\n",
    "del original_df1['nan']\n",
    "\n",
    "original_df1.Total_Stops = original_df1.Total_Stops.fillna(0)\n",
    "\n",
    "#original_df1['Day_week_of_Journey'] = original_df1['Day_week_of_Journey'].apply(str)\n",
    "#original_df1['Day_of_Journey'] = original_df1['Day_of_Journey'].apply(str)\n",
    "#original_df1['Month_of_Journey'] = original_df1['Month_of_Journey'].apply(str)\n",
    "#original_df1['Dep_Time_Hour'] = original_df1['Dep_Time_Hour'].apply(str)\n",
    "#original_df1['Arr_Time_Hour'] = original_df1['Arr_Time_Hour'].apply(str)\n",
    "#original_df1['Days_fg'] = original_df1['Days_fg'].apply(str)\n",
    "\n",
    "original_df1['Destination']=original_df1['Destination'].str.replace('New Delhi', 'Delhi')\n",
    "#print(original_df1.head())\n",
    "#print(original_df1.Destination.unique())\n",
    "#print(original_df1.Source.unique())\n",
    "\n",
    "original_df2=original_df1.copy(deep=True)\n",
    "\n",
    "#pl_19['Month_of_Journey'] = pl_19['Month_of_Journey'].apply(str)\n",
    "original_df2 = pd.merge(original_df2, pl_19,  how='left', on=['Airline','Month_of_Journey'])\n",
    "\n",
    "#fl_19['Month_of_Journey'] = fl_19['Month_of_Journey'].apply(str)\n",
    "original_df2 = pd.merge(original_df2, fl_19,  how='left', on=['Month_of_Journey'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_df2['weekend'] = np.where(original_df2['Day_week_of_Journey']>=5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_df2['Total_Stops']=original_df2['Total_Stops'].astype(np.float)\n",
    "original_df2.P_load = original_df2.P_load.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\"Airline\", \"Source\", \"Destination\", \"Additional_Info\", \"MMT_fg_dept\", \"goibibo_fg_dept\", \"MMT_fg_arr\", \"goibibo_fg_arr\"]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical:\n",
    "    original_df2[col] = label_encoder.fit_transform(original_df2[col].astype(str))\n",
    "\n",
    "train_mod1=original_df2.iloc[:train.shape[0]]\n",
    "test_mod1=original_df2.iloc[train.shape[0]:]\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(train_mod1, target, train_size=0.7, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.9,\n",
       "       colsample_bytree=0.9, gamma=2, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=60, min_child_weight=2, missing=None, n_estimators=440,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=1, reg_lambda=1, scale_pos_weight=1, seed=99, silent=True,\n",
       "       subsample=0.9)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgb.XGBRegressor(colsample_bylevel=0.9, \n",
    "                       colsample_bytree=0.9,\n",
    "                       gamma=2, \n",
    "                       learning_rate=0.01, #0.01\n",
    "                       max_depth=60, #60\n",
    "                       min_child_weight=2, #2\n",
    "                       n_estimators=440, #440\n",
    "                       objective='reg:linear', \n",
    "                       reg_alpha=1, \n",
    "                       reg_lambda=1,\n",
    "                       scale_pos_weight=1, \n",
    "                       seed=99, \n",
    "                       subsample=0.9,\n",
    "                       silent=True)\n",
    "#model.fit(X_train, y_train)\n",
    "model.fit(train_mod1, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542.0741231296357\n",
      "540.6995630668697\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(X_train)\n",
    "ypred_val = model.predict(X_validation)\n",
    "\n",
    "print(sqrt(mean_squared_error(y_train, ypred)))\n",
    "print(sqrt(mean_squared_error(y_validation, ypred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test2=model.predict(test_mod1)\n",
    "y_pred_test2=pd.DataFrame(y_pred_test2)\n",
    "y_pred_test2.columns=['Price']\n",
    "y_pred_test2.to_excel('submission_XGBoost2.xlsx', index=False)#0.9500006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#437.6478614135423\n",
    "#434.30277026851786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model to file\n",
    "pickle.dump(model, open(\"xgb_final.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h> **stacking** </h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test2=model.predict(test_mod1)\n",
    "y_pred_test2=pd.DataFrame(y_pred_test2)\n",
    "y_pred_test2.columns=['xgb']\n",
    "y_pred_test2.to_excel('submission_XGBoost_stck_val.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_test2=model.predict(train_mod1)\n",
    "y_pred_test2=pd.DataFrame(y_pred_test2)\n",
    "y_pred_test2.columns=['xgb']\n",
    "y_pred_test2.to_excel('submission_XGBoost_stck_train.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
